---
title: "Case Study 1"
output: html_document
date: "2022-10-10"
---

# Getting Started

> The goal in the case study is to propose a *regression model for predicting the number of practicing physicians* by county using information from the years 1990 and 1992. The data set provides selected county demographic information (CDI) for 440 of the most populous counties in the United States. Each line of data set has an identification number with a county name and state abbreviation and provides information on 14 variables for a single county. The variables are (in the order they are recorded in the `.txt` file)

+-----------------+-----------------------------------+----------------------------------------------------------------------------------------------------+
| Variable Number | Variable Name                     | Variable Description                                                                               |
+=================+===================================+====================================================================================================+
| 1               | Identification Number             | 1-440\                                                                                             |
+-----------------+-----------------------------------+----------------------------------------------------------------------------------------------------+
| 2               | County                            | County Name                                                                                        |
+-----------------+-----------------------------------+----------------------------------------------------------------------------------------------------+
| 3               | State                             | Two-letter state abbreviation                                                                      |
+-----------------+-----------------------------------+----------------------------------------------------------------------------------------------------+
| 4               | Land Area                         | Land area (square miles)                                                                           |
+-----------------+-----------------------------------+----------------------------------------------------------------------------------------------------+
| 5               | Total Population                  | Estimated 1990 population                                                                          |
+-----------------+-----------------------------------+----------------------------------------------------------------------------------------------------+
| 6               | Percent of Population ages 18-24  | Percent of 1990 CDI population                                                                     |
+-----------------+-----------------------------------+----------------------------------------------------------------------------------------------------+
| 7               | Percent of Population 65 or older | Percent of 1990 CDI population ages 65 or older                                                    |
+-----------------+-----------------------------------+----------------------------------------------------------------------------------------------------+
| 8               | Number of Active Physicians       | Number of professional active non-federal physicians during 1990                                   |
+-----------------+-----------------------------------+----------------------------------------------------------------------------------------------------+
| 9               | Number of Hospital Beds           | Total number of beds, cribs, and bassinets during 1990                                             |
+-----------------+-----------------------------------+----------------------------------------------------------------------------------------------------+
| 10              | Total Serious Crimes              | Total number of serious crimes in 1990 as reported by law enforcement agencies                     |
+-----------------+-----------------------------------+----------------------------------------------------------------------------------------------------+
| 11              | Percent High School Graduates     | Percent of adult population who completed 12 or more years of school                               |
+-----------------+-----------------------------------+----------------------------------------------------------------------------------------------------+
| 12              | Percent of Bachelor's Degrees     | Percent of adult population with bachelor's degrees                                                |
+-----------------+-----------------------------------+----------------------------------------------------------------------------------------------------+
| 13              | Percent Below Poverty Level       | Percent of 1990 CDI population with income below poverty level                                     |
+-----------------+-----------------------------------+----------------------------------------------------------------------------------------------------+
| 14              | Percent Unemployment              | Percent of 1990 CDI labor force that is unemployed                                                 |
+-----------------+-----------------------------------+----------------------------------------------------------------------------------------------------+
| 15              | Per Capita Income                 | Per capita income of 1990 CDI population (dollars)                                                 |
+-----------------+-----------------------------------+----------------------------------------------------------------------------------------------------+
| 16              | Total Personal Income             | Total person income of 1990 CDI population (in millions of dollars)                                |
+-----------------+-----------------------------------+----------------------------------------------------------------------------------------------------+
| 17              | Geographic Region                 | Geographic region classification that is used in the US Bureau of the Census: 1=NE, 2=NC, 3=S, 4=W |
+-----------------+-----------------------------------+----------------------------------------------------------------------------------------------------+

## Setting up Data

Importing our data in R

```{r}
data = read.table("data.txt")
head(data)
```

Removing the **ID column** and the categorical **state** and **county** columns

```{r}
data2 = data[,-c(1, 2, 3)]
head(data2)
```

## Exploring the Data

> Making da graphs

```{r}
hist(data2$V8,main="Histogram of V8", breaks=250, col=2)
```

```{r}
hist(data2$V8,breaks=250, main="Histogram of V8 < 5000", xlim=range(10, 5000), col=2)
```

```{r}
ggplot(data2, aes(V8)) +
  stat_ecdf(geom = "step", pad=FALSE, color=2) +
  ggtitle("Empircal Distribution of V8")
```

Summary Stats for Each Column

```{r}
summary(data2[,1:5])
summary(data2[,6:10])
summary(data2[,11:12])
```

Correlation Matrix (fancy colors go brrrrr)

```{r}
library(corrplot)
M = cor(data.filtered)
corrplot(M, tl.srt = 45)
```

# MLR Time

> Let's start with a full model

```{r}
model.full = lm(V8 ~ ., data=data2)
summary(model.full)
```

Let's filter out predictors that have high p-values

```{r}
p_vals = summary(model.full)$coef[, "Pr(>|t|)"]
names(p_vals[p_vals < .25])
```

Let's use these predictors and compare to the full model

```{r}
model.reduced = lm(V8 ~ V5 + V9 + V11 + V12 + V15 + V16 + V17, data=data2)
summary(model.reduced)
anova(model.reduced, model.full)
```

Let's see if we can trim off `V17`

```{r}
model.reduced2 = lm(V8 ~ V5 + V9 + V11 + V12 + V15 + V16, data=data2)
summary(model.reduced2)
anova(model.reduced2, model.full)
```

We could reduce our model further (by potentially getting rid of `V11`) but we're gonna keep it was is because all the coefficients have a good p-value (so they are probably not zero) and any removals would probably reduce the p-value from the anova (reduced vs full) significantly. For example:

```{r}
model.reduced2 = lm(V8 ~ V5 + V9 + V12 + V15 + V16, data=data2)
summary(model.reduced2)
anova(model.reduced2, model.full)
```

Now all our p-values for individual coefficients are less that $\alpha$ so we won't drop any more $\beta$s from our reduced model :)

# Unusual Observations

## High-Leverage Points

```{r}
p = length(variable.names(model.reduced))
n = nrow(data2)
data.leverages = influence(model.reduced)$hat
```

```{r}
library(faraway)
halfnorm(data.leverages, nlab=6, labs=as.character(1:length(data.leverages)), ylab="Leverages")
```

1 and 2 are kinda out there :0

Let's find the high leverage points

```{r}
data.leverages.high = data.leverages[data.leverages > (2*p)/n]
data.leverages.high = sort(abs(data.leverages.high), decreasing = TRUE)
head(data.leverages.high)
```

Let's find all the rows that are "bad" high-leverage points

```{r}
# Calculate the IQR for the dependent variable 
IQR_y = IQR(data2$V8)

#Define a range with its lower limit being (Q1 - IQR) and upper limit being (Q3 + IQR) 
QT1_y = quantile(data2$V8, 0.25)
QT3_y = quantile(data2$V8, 0.75)

lower_lim_y = QT1_y - IQR_y
upper_lim_y = QT3_y + IQR_y

vector_lim_y = c(lower_lim_y,upper_lim_y)

# Range for y variable 
vector_lim_y
```

```{r}
# Extract observations with high leverage points from the original data frame 
data.highlev = data2[data.leverages > 2*p/n,]

# Select only the observations with leverage points outside the range 
data.highlev_lower = data.highlev[data.highlev$V8 < vector_lim_y[1], ]
data.highlev_upper = data.highlev[data.highlev$V8 > vector_lim_y[2], ]
data.highlev2 = rbind(data.highlev_lower, data.highlev_upper)
data.highlev2
```

## Outliers

> Let's find the outliers in our dataset

```{r}
p = length(variable.names(model.reduced))
n = nrow(data2)
```

```{r}
data.resid = rstudent(model.reduced)
data.resid.sorted = sort(abs(data.resid), decreasing=TRUE)
head(data.resid.sorted)
```

```{r}
bonferroni_cv = qt(.05/(2*n), n-p-1) 
bonferroni_cv
```

```{r}
data.outliers = data.resid[abs(data.resid) > abs(bonferroni_cv)]
data.outliers
```

We got a couple of outliers over here :)

```{r}
cat("Mean: ", mean(data2$V8))
cat("\nOutlier Values: ", data2$V8[as.integer(names(data.outliers))])
```

## Influential Points

> Let's find the influential points using Cook's distance

```{r}
data.cooks = cooks.distance(model.reduced)
data.cooks[data.cooks >= 1]
```

Look's like the first row is influential.

```{r}
plot(data.cooks)
```

Sure looks like it lol

# Let's check the model assumption

## Constant Variance Assumption

```{r}
plot(model.reduced, which=1)
```

```{r}
library(lmtest)
bptest(model.reduced)
```

**yikes**

Square Root Transform?

```{r}
sqrt_transform = lm(sqrt(V8) ~ V5 + V9 + V11 + V12 + V15 + V16, data=data2)
plot(sqrt_transform, which=1)
```

```{r}
bptest(sqrt_transform)
```

:(

Log Transform?

```{r}
log_transform = lm(log(V8) ~ V5 + V9 + V11 + V12 + V15 + V16, data=data2)
plot(log_transform, which=1)
```

```{r}
bptest(log_transform)
```

:(

Inverse Transform?

```{r}
inv_transform = lm(1/V8 ~ V5 + V9 + V11 + V12 + V15 + V16, data=data2)
plot(inv_transform, which=1)
```

```{r}
bptest(inv_transform)
```

um idk about this one tbh

## Normality Assumption

```{r}
hist(model.reduced$residuals,breaks=100, col=2)
```

```{r}
plot(model.reduced, which=2, col=2)
```

```{r}
ks.test(data2$V8, "pnorm")
```

\^ This is mad because an actual continuous distribution shouldn't have repeat points

```{r}
shapiro.test(data2$V8)
```

technically this is only good for n \< 50 (our n is much bigger)

**TLDR: So not normal :(**
